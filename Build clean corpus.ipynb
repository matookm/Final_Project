{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import csv\n",
    "from os import listdir\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each row that fits our criteria, inserts it to the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def populate_tweet_df(tweets):\n",
    "    df = pd.DataFrame()\n",
    "    user_lang = list(map(lambda tweet: tweet['user']['lang'], tweets))\n",
    "    #is_retweet = list(map(lambda tweet: tweet['retweeted_status'], tweets)) #boolean\n",
    "\n",
    "    #if is_retweet == 'False':\n",
    "    df['TweetID'] = list(map(lambda tweet: tweet['id'], tweets))\n",
    "    df['UserID'] = list(map(lambda tweet: tweet['user']['id'], tweets))\n",
    "    df['UserName'] = list(map(lambda tweet: tweet['user']['screen_name'], tweets))\n",
    "    df['Text'] = list(map(lambda tweet: tweet['text'], tweets))\n",
    "    df['Location'] = list(map(lambda tweet: tweet['user']['location'], tweets))\n",
    "    df['User Language'] = list(map(lambda tweet: tweet['user']['lang'], tweets))\n",
    "    df['Tweet Language'] = list(map(lambda tweet: tweet['lang'], tweets))\n",
    "    df['Date'] = list(map(lambda tweet: tweet['created_at'], tweets))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON files\n",
    "this code takes all json files in a directory and converts it to single DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = r'C:\\Users\\matoo\\Documents\\4th year\\final project\\some code\\Test\\\\'\n",
    "tweet_files = os.listdir(directory)\n",
    "tweets = []\n",
    "languages =['bg','cs','fr','ru','es','nl','de','it','ko','ja']\n",
    "for file in tweet_files:\n",
    "    with open(directory+file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            try:\n",
    "                jsonObject = json.loads(line)\n",
    "                lang = jsonObject['user']['lang']\n",
    "                #isRetweet = jsonObject.get('retweeted_status')\n",
    "                if any(lang in s for s in languages)and 'retweeted_status' not in jsonObject:\n",
    "                    tweets.append(json.loads(line))\n",
    "            except ValueError:\n",
    "                print \"error in file: \", file, \"\\nline: \", line\n",
    "        df = populate_tweet_df(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove URLs, mentions (@) and hashtags (#).\n",
    "We keep spaces, remove punctuation and no big letters (all toLower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove URLs\n",
    "df.Text = (df.Text).str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',\n",
    "                                '', case=False)\n",
    "#remove menstions\n",
    "df.Text = (df.Text).str.replace('\\@\\w+', '', case=False)\n",
    "#remove hashtags\n",
    "df.Text = (df.Text).str.replace('\\#\\w+', '', case=False)\n",
    "#remove special signs\n",
    "df.Text = (df.Text).str.replace(r'\\n', ' ', case=False)\n",
    "df.Text = (df.Text).str.replace(r'\\r', ' ', case=False)\n",
    "#remove punctuation\n",
    "df.Text = (df.Text).str.replace(r\"([^a-zA-Z'0-9 ])\", ' ', case=False) #replace with space\n",
    "#ToLower:\n",
    "df.Text = (df.Text).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144113, 8)\n",
      "              TweetID              UserID         UserName  \\\n",
      "0  864251041621192705           561988281        ADOTRADIO   \n",
      "1  864251041620967425  728487742200549378      auto_Chekov   \n",
      "2  864251041436622849          1662294480       halifaxca1   \n",
      "3  864251041344311296           125054226  AlexKamillaKroy   \n",
      "4  864251041184960514           385454278       hurricvnne   \n",
      "\n",
      "                                                Text  \\\n",
      "0     now playing  side are you on   bianco  appl...   \n",
      "1  ugh    zhey're keep moving  i can't get a lock...   \n",
      "2  warranty administrator   steele subaru   halif...   \n",
      "3  fbi   me at jfk terminal  publically say u hac...   \n",
      "4  tell them i was happy and my heart is broken a...   \n",
      "\n",
      "                    Location User Language Tweet Language  \\\n",
      "0                                       it             en   \n",
      "1  USS Enterprise (NCC-1701)            ko             en   \n",
      "2             Halifax Canada            nl             en   \n",
      "3             St. Petersburg            ru             en   \n",
      "4            ⚡@idkwhatsdisok            es             en   \n",
      "\n",
      "                             Date  \n",
      "0  Mon May 15 22:47:59 +0000 2017  \n",
      "1  Mon May 15 22:47:59 +0000 2017  \n",
      "2  Mon May 15 22:47:59 +0000 2017  \n",
      "3  Mon May 15 22:47:59 +0000 2017  \n",
      "4  Mon May 15 22:47:59 +0000 2017  \n"
     ]
    }
   ],
   "source": [
    "print df.shape\n",
    "print df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pickle files\n",
    "if we need to add old pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "languages =['bg','cs','fr','ru','es','nl','de','it','ko','ja']\n",
    "\n",
    "old_df_path = r'C:\\Users\\matoo\\Documents\\4th year\\final project\\some code\\Pickles\\corpus_to_pickle_all_langs_new4'\n",
    "old_df = pd.read_pickle(old_df_path)\n",
    "#cols = df.columns\n",
    "#dfBG = pd.read_pickle(r'C:\\Users\\matoo\\Documents\\4th year\\final project\\some code\\Pickles\\BGtweets')\n",
    "#dfKO = pd.read_pickle(r'C:\\Users\\matoo\\Documents\\4th year\\final project\\some code\\Pickles\\KOtweets')\n",
    "#dfCS = pd.read_pickle(r'C:\\Users\\matoo\\Documents\\4th year\\final project\\some code\\Pickles\\CStweets')\n",
    "#\n",
    "#dfBG.columns = cols\n",
    "#dfKO.columns = cols\n",
    "#dfCS.columns = cols\n",
    "\n",
    "frames = [df, old_df]#, dfKO, dfBG, dfCS]\n",
    "df = pd.concat(frames)\n",
    "\n",
    "df = df[df['User Language'].isin(languages)]\n",
    "\n",
    "df = df.drop_duplicates(subset ='TweetID', keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the DF dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(956110, 8)\n",
      "              TweetID              UserID         UserName  \\\n",
      "0  864251041621192705           561988281        ADOTRADIO   \n",
      "1  864251041620967425  728487742200549378      auto_Chekov   \n",
      "2  864251041436622849          1662294480       halifaxca1   \n",
      "3  864251041344311296           125054226  AlexKamillaKroy   \n",
      "4  864251041184960514           385454278       hurricvnne   \n",
      "\n",
      "                                                Text  \\\n",
      "0     now playing  side are you on   bianco  appl...   \n",
      "1  ugh    zhey're keep moving  i can't get a lock...   \n",
      "2  warranty administrator   steele subaru   halif...   \n",
      "3  fbi   me at jfk terminal  publically say u hac...   \n",
      "4  tell them i was happy and my heart is broken a...   \n",
      "\n",
      "                    Location User Language Tweet Language  \\\n",
      "0                                       it             en   \n",
      "1  USS Enterprise (NCC-1701)            ko             en   \n",
      "2             Halifax Canada            nl             en   \n",
      "3             St. Petersburg            ru             en   \n",
      "4            ⚡@idkwhatsdisok            es             en   \n",
      "\n",
      "                             Date  \n",
      "0  Mon May 15 22:47:59 +0000 2017  \n",
      "1  Mon May 15 22:47:59 +0000 2017  \n",
      "2  Mon May 15 22:47:59 +0000 2017  \n",
      "3  Mon May 15 22:47:59 +0000 2017  \n",
      "4  Mon May 15 22:47:59 +0000 2017  \n"
     ]
    }
   ],
   "source": [
    "print df.shape\n",
    "print df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting our DF to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle(r'C:\\Users\\matoo\\Documents\\4th year\\final project\\some code\\Pickles\\corpus_to_pickle_all_langs_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to check what is in an existing pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(r'C:\\Users\\matoo\\Documents\\4th year\\final project\\some code\\Pickles\\final_pickle_no_duplicats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some stats on the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total languages: \n",
      "  User Language       0\n",
      "0            bg    9868\n",
      "1            cs   24262\n",
      "2            de   84479\n",
      "3            es  246201\n",
      "4            fr  124844\n",
      "5            it   47325\n",
      "6            ja   35152\n",
      "7            ko   32464\n",
      "8            nl   50691\n",
      "9            ru   80205\n",
      "total users: \n",
      "  User Language  UserID\n",
      "0            bg     520\n",
      "1            cs    1707\n",
      "2            de   41315\n",
      "3            es  141251\n",
      "4            fr   67992\n",
      "5            it   24118\n",
      "6            ja   21167\n",
      "7            ko    5623\n",
      "8            nl   22757\n",
      "9            ru   23403\n"
     ]
    }
   ],
   "source": [
    "num_of_tweets = df.copy(deep = True)\n",
    "total_lang = pd.DataFrame(num_of_tweets.groupby('User Language').size().reset_index())\n",
    "total_users = pd.DataFrame(num_of_tweets.groupby('User Language').UserID.nunique().reset_index())\n",
    "print \"total languages: \"\n",
    "print total_lang\n",
    "print \"total users: \"\n",
    "print total_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID User Language  total_tweets\n",
      "0    5199            fr             1\n",
      "1    5430            de             1\n",
      "2   10781            nl             2\n",
      "3   53883            it             1\n",
      "4   55293            es             1\n",
      "              total_tweets                                    \n",
      "                       min  max          var       mean median\n",
      "User Language                                                 \n",
      "bg                       1  187  1583.698888  18.976923      1\n",
      "cs                       1  298  1066.607492  14.213240      1\n",
      "de                       1  265    18.199261   2.044754      1\n",
      "es                       1  401    19.892982   1.743004      1\n",
      "fr                       1  299    18.272724   1.836157      1\n",
      "it                       1  373    21.594750   1.962227      1\n",
      "ja                       1  363    17.201414   1.660698      1\n",
      "ko                       1  267   290.382311   5.773431      1\n",
      "nl                       1  327    28.656938   2.227490      1\n",
      "ru                       1  147    39.856357   3.427125      1\n"
     ]
    }
   ],
   "source": [
    "aggregate = {'UserID':{'total_tweets':'count'}}\n",
    "total_users_in_langs = pd.DataFrame(num_of_tweets.groupby(['UserID','User Language']).agg(aggregate).reset_index())\n",
    "total_users_in_langs.columns = ['UserID', 'User Language','total_tweets']\n",
    "print total_users_in_langs.head()\n",
    "aggregated_features = {'total_tweets':['min','max','var','mean','median']}\n",
    "stats_per_lang = pd.DataFrame(total_users_in_langs.groupby('User Language').agg(aggregated_features))\n",
    "print stats_per_lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output all stats to excel. May take a while to write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('Statistics_final_no dups.xlsx')\n",
    "total_lang.to_excel(writer,'Total languages')\n",
    "total_users.to_excel(writer,'Users per language')\n",
    "stats_per_lang.to_excel(writer,'Language users stats')\n",
    "total_users_in_langs.to_excel(writer,'All users per language')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  TweetID              UserID     UserName  \\\n",
      "23003  839246187689562112  725658846367244288  MiafKhalifa   \n",
      "34969  840297081533280260  725658846367244288  MiafKhalifa   \n",
      "43747  840659371063463937  725658846367244288  MiafKhalifa   \n",
      "52017  841021841221267456  725658846367244288  MiafKhalifa   \n",
      "54699  840913236035801088  725658846367244288  MiafKhalifa   \n",
      "57409  841420478145273858  725658846367244288  MiafKhalifa   \n",
      "64116  841782797245247490  725658846367244288  MiafKhalifa   \n",
      "64128  841782795630440448  725658846367244288  MiafKhalifa   \n",
      "95252  842761290628186112  725658846367244288  MiafKhalifa   \n",
      "\n",
      "                                                    Text Location  \\\n",
      "23003                          you cheat on your girl?         US   \n",
      "34969   To Convince Your Girlfriend To Do The Naughti...       US   \n",
      "43747                            You Mean A Lot To Him         US   \n",
      "52017               Between Making Love And Having Sex         US   \n",
      "54699   She Saw Her Son Sexist Post, She Decided To S...       US   \n",
      "57409                                    Girl Got Cold         US   \n",
      "64116                           Minaj’s Booty Implants         US   \n",
      "64128                           Minaj’s Booty Implants         US   \n",
      "95252        Is Reportedly Not Jasmine’s Baby's Father         US   \n",
      "\n",
      "      User Language Tweet Language                            Date  \n",
      "23003            bg             en  Tue Mar 07 22:47:38 +0000 2017  \n",
      "34969            bg             en  Fri Mar 10 20:23:30 +0000 2017  \n",
      "43747            bg             en  Sat Mar 11 20:23:07 +0000 2017  \n",
      "52017            bg             en  Sun Mar 12 20:23:27 +0000 2017  \n",
      "54699            bg             en  Sun Mar 12 13:11:53 +0000 2017  \n",
      "57409            bg             en  Mon Mar 13 22:47:29 +0000 2017  \n",
      "64116            bg             en  Tue Mar 14 22:47:13 +0000 2017  \n",
      "64128            bg             en  Tue Mar 14 22:47:12 +0000 2017  \n",
      "95252            bg             en  Fri Mar 17 15:35:24 +0000 2017  \n"
     ]
    }
   ],
   "source": [
    "print num_of_tweets.loc[df['UserID'] == 725658846367244288]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
