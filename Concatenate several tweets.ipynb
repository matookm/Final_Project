{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paths to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_path = r'C:\\Users\\matoo\\Documents\\4th year\\final project\\some code\\Pickles\\concat\\5langs\\\\'\n",
    "pickle_path = r'C:\\Users\\matoo\\Documents\\4th year\\final project\\some code\\Pickles\\corpus_to_pickle_all_langs_final'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a new DF with two columns - 'User Language' and 'Text' without the same TweetID or a duplicate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(pickle_path)\n",
    "#drop duplicate TweetID\n",
    "df = df.drop_duplicates(subset ='TweetID', keep='last')\n",
    "#remove all duplicate text\n",
    "df = df.drop_duplicates(subset ='Text', keep=False)\n",
    "df.drop(df.columns[[0,1,2,4,6,7]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check how many we have without dups\n",
    "#df.to_pickle(r'C:\\Users\\matoo\\Documents\\4th year\\final project\\some code\\Pickles\\final_pickle_no_duplicats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concatinating a number of tweets together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_tweets(text_list, number_to_concat):\n",
    "    text_list_len = len(text_list)\n",
    "    fractions = int(text_list_len/number_to_concat)\n",
    "    new_text = list()\n",
    "    for how_many in range(0,fractions):\n",
    "        new_tweet = \"\"\n",
    "        for i in range(0,number_to_concat):\n",
    "            new_tweet = new_tweet +\" \"+ text_list.pop()\n",
    "        new_text.append(new_tweet)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_all_langs(languages, sample_size, concat_length):\n",
    "    cols = ['User Language', 'Text']\n",
    "    all_dfs = pd.DataFrame(columns=cols)\n",
    "    for lang in languages:\n",
    "        curr_lang_tweets = df.loc[df['User Language'] == lang]  # build DF with same lang\n",
    "        curr_lang_tweets = curr_lang_tweets.sample(n=sample_size).reset_index()  # take n tweets randomly\n",
    "        curr_lang_tweets_list = curr_lang_tweets['Text'].tolist()\n",
    "        temp = pd.DataFrame(columns=cols)\n",
    "        tomultiply =  int(sample_size / concat_length)\n",
    "        l_lang = [lang] * tomultiply\n",
    "        temp['Text'] = concat_tweets(curr_lang_tweets_list, concat_length)  # all_dfs_text[index]\n",
    "        temp['User Language'] = l_lang\n",
    "        all_dfs = pd.concat([all_dfs, temp], ignore_index=True)\n",
    "    all_dfs.to_pickle(write_path + 'concat_' + str(concat_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Text', u'User Language'], dtype='object')\n",
      "                    0\n",
      "User Language        \n",
      "bg               9868\n",
      "cs              24262\n",
      "de              84479\n",
      "es             246201\n",
      "fr             124844\n",
      "it              47325\n",
      "ja              35152\n",
      "ko              32464\n",
      "nl              50691\n",
      "ru              80205\n"
     ]
    }
   ],
   "source": [
    "print df.columns\n",
    "print pd.DataFrame(df.groupby('User Language').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25345\n"
     ]
    }
   ],
   "source": [
    "languages =['bg','cs','fr','ru','es','nl','de','it','ko','ja']\n",
    "sample_size = 50690   #how many tweets to take from each language\n",
    "\n",
    "for con in (1, 5, 10, 30, 50, 70, 90, 120):\n",
    "    concat_all_langs(languages,sample_size,con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5069, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(write_path + 'concat_10')\n",
    "df.loc[df['User Language'] == 'fr'].shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
